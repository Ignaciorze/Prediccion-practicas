---
title: "Práctica 3"
author: "Ignacio Ruiz de Zuazu Echevarría"
date: "8/11/2020"
output:
 prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

[link a GitHub](https://github.com/ignacio-ruiz-de-zuazu/Prediccion-practicas.git)

<div>
<p style = 'text-align:center;'>
<img src="https://www.rutherford.school.nz/wp-content/uploads/2018/08/PISA.jpg" alt="JuveYell" width="600px">
</p>
</div>


## Objetivo del trabajo

El objetivo es modelizar la relación entre la puntuación media (OSS) y el resto de variables, utilizando modelos de splines y GAM. Se debe realizar CV cuando se pueda.

## Librerías que se van a emplear


```{r pressure, echo=FALSE}
library(readr)
library(tidyverse)
library(broom) 
library(flextable) 
library(mgcv) 
library(reshape2) 
library(splines)
library(skimr)
library(rsample)
library(gamlss)
```


## Dataset 

El conjunto de datos se ha construido utilizando la puntuación media en Ciencias por país del Programa para la Evaluación Internacional de Estudiantes (PISA) 2006, junto con el GNI per cápita (paridad del poder adquisitivo, dólares de 2005), el índice educativo, el índice de salud y el índice de desarrollo humano de la ONU (HDI).

Las variables clave son las siguientes:

* Overall Science Score (average score for 15 year olds)
* Interest in science
* Support for scientific inquiry
* Income Index
* Health Index
* Education Index
* Human Development Index (composed of the Income index, Health Index, and Education Index)

El objetivo es modelizar la relación entre la puntuación media (OSS) y el resto de variables, utilizando modelos de splines y GAM. Se debe realizar CV cuando se pueda.

```{r }
pisa <- read.csv('./data/pisasci2006.csv')
head(pisa)
tail(pisa)
```


## Análisis descriptivo

```{r}
colnames(pisa)
skim(pisa)
```

## Modelo Lineal

```{r }
modelo_lm <- lm(Overall ~ Interest + Support + Income + Health + Edu + HDI, data = pisa)
summary(modelo_lm)


width(flextable(tidy(modelo_lm)), width = 1.5)

width(flextable(glance(modelo_lm)), width = 1.5)

termplot(modelo_lm, partial.resid = TRUE, se = TRUE)
```

La variable Support es la variable menos relevante dentro de este modelo. Podemos observar en las gráficas que los residuos parciales dentro del modelo para las varaibles de Interest, Support y Health tienen poca dispersión de error mientras que para las variables correspondientes a Income, Edu y sobretodo a HDI. 


## Splines de regresión de las variables

Se emplearán splines lineales.

### Gráficas de sipersión Overall-Interest
```{r }
# Para la varaible Interest
attach(pisa)
interestplot <- ggplot(data = pisa, mapping = aes(x = Interest, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
interestplot
```

### Nudos para Interest con 6 grados de libertad

```{r}
# Para la varaible Interest
attr(bs(pisa$Interest, df = 6), 'knots')

knotsint <- c(501, 522, 565)
pisa$X1int <- pmax(0, pisa$Interest - knotsint[1])
pisa$X2int <- pmax(0, pisa$Interest - knotsint[2])
pisa$X3int <- pmax(0, pisa$Interest - knotsint[3])
```

### Gráfica aplicando splines

```{r}
# Para la varaible Interest
InterestLint <- range(pisa$Interest, na.rm = TRUE)
interest.grid <- seq(from = InterestLint[1], to = InterestLint[2])
fitint <- lm(Overall~bs(Interest, knots=c(501, 522, 565)), data = pisa, na.action = na.omit)
predint <- predict(fitint, newdata = list(Interest = interest.grid), se = TRUE)


plot(Interest, Overall, col = 'gray')
lines(interest.grid, predint$fit, lwd = 2)
lines(interest.grid, predint$fit + 2*predint$se, lty = 'dashed')
lines(interest.grid, predint$fit - 2*predint$se, lty = 'dashed')
```

Se realiza el mismo procedimietno para el resto de variables

### Gráficas de dispersión

```{r}
# Para la variable Support

supportplot <- ggplot(data = pisa, mapping = aes(x = Support, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
supportplot

# Para la variable Income

incomeplot <- ggplot(data = pisa, mapping = aes(x = Income, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
incomeplot

# Para la variable Health

healthplot <- ggplot(data = pisa, mapping = aes(x = Health, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
healthplot

# Para la variable Edu

eduplot <- ggplot(data = pisa, mapping = aes(x = Edu, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
eduplot

# Para la varaible HDI

hdiplot <- ggplot(data = pisa, mapping = aes(x = HDI, y = Overall)) +
  layer(geom = "point",stat = "identity",position = "identity") +
  theme_bw() + theme(legend.key = element_blank())
hdiplot
```

Se puede observar una gran dispersión en las variables Health y Support, también en variables como Income y Edu se puede apreciar que existen ciertos puntos extremos.


### Gráficas aplicando splines

```{r}
attr(bs(pisa$Support, df = 6), 'knots')

knotssup <- c(494, 512, 529)
pisa$X1sup <- pmax(0, pisa$Interest - knotssup[1])
pisa$X2sup <- pmax(0, pisa$Interest - knotssup[2])
pisa$X3sup <- pmax(0, pisa$Interest - knotssup[3])

SupportLims <- range(pisa$Support, na.rm = TRUE)
Support.grid <- seq(from = SupportLims[1], to = SupportLims[2])
fit <- lm(Overall~bs(Support, knots=c(494, 512, 529)), data = pisa)
pred <- predict(fit, newdata = list(Support = Support.grid), se = TRUE)


plot(Support, Overall, col = 'gray')
lines(Support.grid, pred$fit, lwd = 2)
lines(Support.grid, pred$fit + 2*pred$se, lty = 'dashed')
lines(Support.grid, pred$fit - 2*pred$se, lty = 'dashed')


attr(bs(pisa$Income, df = 6), 'knots')

knotsincome <- c(0.658, 0.765, 0.833)
pisa$X1inc <- pmax(0, pisa$Income - knotsincome[1])
pisa$X2inc <- pmax(0, pisa$Income - knotsincome[2])
pisa$X3inc <- pmax(0, pisa$Income - knotsincome[3])


IncomeLims <- range(Income, na.rm = TRUE)
income.grid <- seq(from = IncomeLims[1], to = IncomeLims[2], 0.01)
fitincome <- lm(Overall~bs(Income, knots=c(0.658, 0.765, 0.833)), data = pisa)
predincome <- predict(fitincome, newdata = list(Income = income.grid), se = TRUE)

plot(Income, Overall, col = 'gray')
lines(income.grid, predincome$fit, lwd = 2)
lines(income.grid, predincome$fit + 2*predincome$se, lty = 'dashed')
lines(income.grid, predincome$fit - 2*predincome$se, lty = 'dashed')

attr(bs(pisa$Health, df = 6), 'knots')

knotshealth <- c(0.838, 0.893, 0.942)
pisa$X1health <- pmax(0, pisa$Health - knotshealth[1])
pisa$X2health <- pmax(0, pisa$Health - knotshealth[2])
pisa$X3health <- pmax(0, pisa$Health - knotshealth[3])

healthLims <- range(Health, na.rm = TRUE)

health.grid <- seq(from = healthLims[1], to = healthLims[2], 0.01)
fithealth <- lm(Overall ~ bs(Health, knots = c(0.838, 0.893, 0.942)), data = pisa)
predhealth <- predict(fithealth, newdata = list(Health = health.grid), se = TRUE)

plot(Health, Overall, col = 'gray')
lines(health.grid, predhealth$fit, lwd = 2)
lines(health.grid, predhealth$fit + 2*predhealth$se, lty = 'dashed')
lines(health.grid, predhealth$fit - 2*predhealth$se, lty = 'dashed')

attr(bs(pisa$Edu, df = 6), 'knots')

knotseduc <- c(0.718, 0.812, 0.878)
pisa$X1Edu <- pmax(0, pisa$Edu - knotseduc[1])
pisa$X2Edu <- pmax(0, pisa$Edu - knotseduc[2])
pisa$X3Edu <- pmax(0, pisa$Edu - knotseduc[3])

eduLims <- range(Edu, na.rm = TRUE)
edu.grid <- seq(from = eduLims[1], to = eduLims[2], 0.01)
fitedu <- lm(Overall ~ bs(Edu, knots = c(0.718, 0.812, 0.878)), data = pisa)
prededu <- predict(fitedu, newdata = list(Edu = edu.grid), se = TRUE)

plot(Edu, Overall, col = 'gray')
lines(edu.grid, prededu$fit, lwd = 2)
lines(edu.grid, prededu$fit + 2*prededu$se, lty = 'dashed')
lines(edu.grid, prededu$fit - 2*prededu$se, lty = 'dashed')

attr(bs(pisa$HDI, df = 6), 'knots')

knotsHDI <- c(0.7485, 0.8170, 0.8770)
pisa$X1HDI <- pmax(0, pisa$HDI - knotsHDI[1])
pisa$X2HDI <- pmax(0, pisa$HDI - knotsHDI[2])
pisa$X3HDI <- pmax(0, pisa$HDI - knotsHDI[3])


hdiLims <- range(HDI, na.rm = TRUE)
hdi.grid <- seq(from = hdiLims[1], to = hdiLims[2], 0.01)
fithdi <- lm(Overall ~ bs(HDI, knots = c(0.7485, 0.8170, 0.8770)), data = pisa)
predhdi <- predict(fithdi, newdata = list(HDI = hdi.grid), se = TRUE)

plot(HDI, Overall, col = 'gray')
lines(hdi.grid, predhdi$fit, lwd = 2)
lines(hdi.grid, predhdi$fit + 2*predhdi$se, lty = 'dashed')
lines(hdi.grid, predhdi$fit - 2*predhdi$se, lty = 'dashed')
```


## Modelos GAM

Los GAMs (del inglés generalized additive models) son una generalización de los GLMs para incorporar formas no lineales de los predictores.

```{r}
modelo_gam1 <- gam(Overall ~ s(Interest) + s(Support) + s(Income) + s(Health) + 
                    s(Edu) + HDI, data = pisa, na.action = na.exclude)

summary(modelo_gam1)

par(mfrow = c(2, 3))
plot(modelo_gam1, se = TRUE, col = 'red')

gam.check(modelo_gam1)
```
Se realiza otro modelo sin la varaible Health con splines

```{r}

modelo_gam2 <- gam(Overall ~ s(Interest) + s(Support) + s(Income) + Health + 
                     s(Edu) + HDI, data = pisa, na.action = na.exclude)

summary(modelo_gam2)

par(mfrow = c(2, 2))
plot(modelo_gam2, se = TRUE, col = 'green')

gam.check(modelo_gam2)

```

Se observa un modelo mejor que el anterior. Vamos a observar los residuos de las variables una a una y ver el número de K que se pueden aplicar a cada variable.

```{r }
gam_int_k50 <- gam(Overall ~ s(Interest, k = 50), data = pisa)

gam_sup_k50 <- gam(Overall ~ s(Support, k = 20), data = pisa) 

gam_inc_k20 <- gam(Overall ~ s(Income, k = 20), data = pisa)

gam_edu_k50 <- gam(Overall ~ s(Edu, k = 50), data = pisa)
```

```{r }
# Visualize the GAMs

plot(gam_int_k50, residuals = TRUE, pch = 1)

plot(gam_sup_k50, residuals = TRUE, pch = 1)

plot(gam_inc_k20, residuals = TRUE, pch = 1)

plot(gam_edu_k50, residuals = TRUE, pch = 1)

```

Se observa que en el caso de la variable Support no aporta mucha precision al estudio de nuestra variable a expliacar.

## Cross Validation

Para realizar el cross validation se empleará la función gamlssCV de la librería gamlss.
                        
```{r }
cv_modelo_1 <- gamlssCV(Overall ~ Interest + Support + Income + Health + 
                     Edu + HDI, data = na.omit(pisa), K.fold = 10, parallel = "multicore", ncpus = 4, set.seed = 1234)
                        
CV(cv_modelo_1)

```                        
Con La función CV () se extrae la desviación global validada cruzada de uno o más objetos gamlssCV ajustados y se puede utilizar para comparar modelos.









